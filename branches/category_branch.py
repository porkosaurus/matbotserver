from anthropic import Anthropic
import os

# Initialize the Anthropic client
anthropic = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))

# Define the path to the research files folder (relative path from where the script is run)
RESEARCH_FOLDER_PATH = os.path.join(os.path.dirname(__file__), '..', 'research')

def answer_category_question(question, context, research_file):
    """
    Answers research-related questions by fetching the content from the specified text file
    and generating a concise response with the help of an LLM.
    """
    # Ensure the research file has the correct .txt extension
    if not research_file.endswith('.txt'):
        research_file += '.txt'

    # Get the full path to the research file
    research_file_path = os.path.join(RESEARCH_FOLDER_PATH, research_file)

    # Check if the research file exists
    if not os.path.exists(research_file_path):
        return "Sorry, I couldn't find any relevant research information for your query."

    # Read the content of the research file
    try:
        with open(research_file_path, 'r', encoding='utf-8') as file:
            file_content = file.read()
    except Exception as e:
        return f"An error occurred while reading the research file: {e}"

    # Prepare the content for the LLM request
    try:
        response = anthropic.messages.create(
            model="claude-3-haiku-20240307",
            max_tokens=1000,
            messages=[
                {"role": "user", "content": f"""You are a research assistant providing insights based on the research documents provided. Respond concisely and provide targeted information.

                User's Question: {question}

                Relevant Research Document Content:
                {file_content}

                Based on the document, provide a helpful response."""}
            ]
        )
        # Return the response generated by the LLM
        return response.content[0].text
    except Exception as e:
        return f"An error occurred while generating the response: {e}"
